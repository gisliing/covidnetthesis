  1) Stages/Devel-2020

Currently Loaded Modules:
  1) Stages/Devel-2019a          (S)    13) libreadline/.8.0   (H)  25) XZ/.5.2.4              (H)  37) Python/3.6.8                        49) Szip/.2.1.1                        (H)
  2) GCC/8.3.0                          14) Tcl/8.6.9               26) libxml2/.2.9.9         (H)  38) imkl/.2019.3.199               (H)  50) HDF5/1.10.5-serial
  3) GCCcore/.8.3.0              (H)    15) SQLite/.3.27.2     (H)  27) libxslt/.1.1.33        (H)  39) SciPy-Stack/2019a-Python-3.6.8      51) h5py/2.9.0-serial-Python-3.6.8
  4) binutils/.2.32              (H)    16) expat/.2.2.6       (H)  28) libffi/.3.2.1          (H)  40) x264/.20190429                 (H)  52) Keras/2.2.4-GPU-Python-3.6.8
  5) nvidia/.418.87.00           (H,g)  17) libpng/.1.6.36     (H)  29) libyaml/.0.2.2         (H)  41) FFmpeg/.4.1.3                  (H)  53) Horovod/0.16.2-GPU-Python-3.6.8    (g)
  6) CUDA/10.1.105               (g)    18) freetype/.2.10.0   (H)  30) Java/1.8                    42) numactl/2.0.12                      54) TensorFlow/1.13.1-GPU-Python-3.6.8 (g)
  7) UCX/1.6.1                          19) gperf/.3.1         (H)  31) PostgreSQL/11.2             43) MPFR/4.0.2                          55) dask/1.1.5-Python-3.6.8
  8) pscom/.5.4.2-1-CUDA         (H)    20) util-linux/.2.33.1 (H)  32) protobuf/.3.7.1        (H)  44) NCCL/2.4.6-1-CUDA-10.1.105     (g)  56) scikit/2019a-Python-3.6.8
  9) ParaStationMPI/5.4.0-1-CUDA        21) fontconfig/.2.13.1 (H)  33) gflags/.2.2.2          (H)  45) cuDNN/7.5.1.10-CUDA-10.1.105   (g)
 10) bzip2/.1.0.6                (H)    22) X11/20190311            34) libspatialindex/.1.9.0 (H)  46) libunwind/.1.3.1               (H)
 11) zlib/.1.2.11                (H)    23) Tk/.8.6.9          (H)  35) NASM/.2.14.02          (H)  47) glog/.0.4.0                    (H)
 12) ncurses/.6.1                (H)    24) GMP/6.1.2               36) libjpeg-turbo/.2.0.2   (H)  48) PyTorch/1.1.0-GPU-Python-3.6.8 (g)

  Where:
   H:  Hidden Module
   S:  Module is Sticky, requires --force to unload or purge
   g:  built for GPU

 

cpu_bind=NONE - dp-dam03, task  0  0 [11214]: mask 0xffffffffffffffffffffffff set
cpu_bind=NONE - dp-dam08, task  5  0 [6778]: mask 0xffffffffffffffffffffffff set
cpu_bind=NONE - dp-dam04, task  1  0 [1517]: mask 0xffffffffffffffffffffffff set
cpu_bind=NONE - dp-dam06, task  3  0 [27071]: mask 0xffffffffffffffffffffffff set
cpu_bind=NONE - dp-dam07, task  4  0 [26128]: mask 0xffffffffffffffffffffffff set
cpu_bind=NONE - dp-dam05, task  2  0 [16731]: mask 0xffffffffffffffffffffffff set
<PSP:r0000001:extoll:EXTOLL disabled : rma2_open() : Communication with the OS driver failed>
<PSP:r0000003:extoll:EXTOLL disabled : rma2_open() : Communication with the OS driver failed>
<PSP:r0000005:extoll:EXTOLL disabled : rma2_open() : Communication with the OS driver failed>
<PSP:r0000002:extoll:EXTOLL disabled : rma2_open() : Communication with the OS driver failed>
<PSP:r0000004:extoll:EXTOLL disabled : rma2_open() : Communication with the OS driver failed>
<PSP:r0000000:extoll:EXTOLL disabled : rma2_open() : Communication with the OS driver failed>
2022-01-15 15:20:54.328816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-01-15 15:20:54.333290: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x8b93e80 executing computations on platform Host. Devices:
2022-01-15 15:20:54.333321: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2022-01-15 15:20:54.364872: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-01-15 15:20:54.369494: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x823ebc0 executing computations on platform Host. Devices:
2022-01-15 15:20:54.369526: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2022-01-15 15:20:54.427768: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-01-15 15:20:54.432622: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x99dd2a0 executing computations on platform Host. Devices:
2022-01-15 15:20:54.432673: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2022-01-15 15:20:54.450529: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x8bef2d0 executing computations on platform CUDA. Devices:
2022-01-15 15:20:54.450599: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2022-01-15 15:20:54.450974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:af:00.0
totalMemory: 31.72GiB freeMemory: 31.41GiB
2022-01-15 15:20:54.450991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2022-01-15 15:20:54.483619: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x829a010 executing computations on platform CUDA. Devices:
2022-01-15 15:20:54.483683: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2022-01-15 15:20:54.483999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:af:00.0
totalMemory: 31.72GiB freeMemory: 31.41GiB
2022-01-15 15:20:54.484015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2022-01-15 15:20:54.496422: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-01-15 15:20:54.501868: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x94d5240 executing computations on platform Host. Devices:
2022-01-15 15:20:54.501901: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2022-01-15 15:20:54.559008: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x9a386f0 executing computations on platform CUDA. Devices:
2022-01-15 15:20:54.559045: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2022-01-15 15:20:54.559231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:af:00.0
totalMemory: 31.72GiB freeMemory: 31.41GiB
2022-01-15 15:20:54.559246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2022-01-15 15:20:54.644683: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x9530670 executing computations on platform CUDA. Devices:
2022-01-15 15:20:54.644726: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2022-01-15 15:20:54.644946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:af:00.0
totalMemory: 31.72GiB freeMemory: 31.41GiB
2022-01-15 15:20:54.644965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2022-01-15 15:20:55.545058: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-01-15 15:20:55.549870: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x872c370 executing computations on platform Host. Devices:
2022-01-15 15:20:55.549904: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2022-01-15 15:20:55.675550: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x87877c0 executing computations on platform CUDA. Devices:
2022-01-15 15:20:55.675615: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2022-01-15 15:20:55.675888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:af:00.0
totalMemory: 31.72GiB freeMemory: 31.41GiB
2022-01-15 15:20:55.675905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2022-01-15 15:20:55.803877: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2400000000 Hz
2022-01-15 15:20:55.808418: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x964b6f0 executing computations on platform Host. Devices:
2022-01-15 15:20:55.808442: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2022-01-15 15:20:55.940583: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x96a6b20 executing computations on platform CUDA. Devices:
2022-01-15 15:20:55.940625: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0
2022-01-15 15:20:55.940825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38
pciBusID: 0000:af:00.0
totalMemory: 31.72GiB freeMemory: 31.41GiB
2022-01-15 15:20:55.940843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2022-01-15 15:20:56.630043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-01-15 15:20:56.630077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2022-01-15 15:20:56.630084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2022-01-15 15:20:56.630207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30469 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)
2022-01-15 15:20:56.632615: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2022-01-15 15:21:01.272387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-01-15 15:21:01.272418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2022-01-15 15:21:01.272424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2022-01-15 15:21:01.272554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30469 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)
2022-01-15 15:21:01.275148: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2022-01-15 15:21:05.783507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-01-15 15:21:05.783539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2022-01-15 15:21:05.783544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2022-01-15 15:21:05.783673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30469 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)
2022-01-15 15:21:05.786167: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Traceback (most recent call last):
  File "test_cov.py", line 83, in <module>
    pred = predict(complete_path, weightspath, metaname, ckptname, in_tensorname, out_tensorname)   
  File "test_cov.py", line 47, in predict
    x = cv2.imread(args.imagepath)
NameError: name 'args' is not defined
Traceback (most recent call last):
  File "test_cov.py", line 83, in <module>
    pred = predict(complete_path, weightspath, metaname, ckptname, in_tensorname, out_tensorname)   
  File "test_cov.py", line 47, in predict
    x = cv2.imread(args.imagepath)
NameError: name 'args' is not defined
2022-01-15 15:21:26.239565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-01-15 15:21:26.239594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2022-01-15 15:21:26.239600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2022-01-15 15:21:26.239737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30469 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)
2022-01-15 15:21:26.242196: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Traceback (most recent call last):
  File "test_cov.py", line 83, in <module>
    pred = predict(complete_path, weightspath, metaname, ckptname, in_tensorname, out_tensorname)   
  File "test_cov.py", line 47, in predict
    x = cv2.imread(args.imagepath)
NameError: name 'args' is not defined
2022-01-15 15:21:33.456069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-01-15 15:21:33.456098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2022-01-15 15:21:33.456104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2022-01-15 15:21:33.456247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30469 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)
2022-01-15 15:21:33.458496: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Traceback (most recent call last):
  File "test_cov.py", line 83, in <module>
    pred = predict(complete_path, weightspath, metaname, ckptname, in_tensorname, out_tensorname)   
  File "test_cov.py", line 47, in predict
    x = cv2.imread(args.imagepath)
NameError: name 'args' is not defined
Traceback (most recent call last):
  File "test_cov.py", line 83, in <module>
    pred = predict(complete_path, weightspath, metaname, ckptname, in_tensorname, out_tensorname)   
  File "test_cov.py", line 47, in predict
    x = cv2.imread(args.imagepath)
NameError: name 'args' is not defined
2022-01-15 15:21:52.962496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-01-15 15:21:52.962527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2022-01-15 15:21:52.962535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2022-01-15 15:21:52.962668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30469 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0)
2022-01-15 15:21:52.965791: I tensorflow/core/common_runtime/process_util.cc:71] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
Traceback (most recent call last):
  File "test_cov.py", line 83, in <module>
    pred = predict(complete_path, weightspath, metaname, ckptname, in_tensorname, out_tensorname)   
  File "test_cov.py", line 47, in predict
    x = cv2.imread(args.imagepath)
NameError: name 'args' is not defined
srun: error: dp-dam07: task 4: Exited with exit code 1
srun: error: dp-dam06: task 3: Exited with exit code 1
srun: error: dp-dam08: task 5: Exited with exit code 1
srun: error: dp-dam04: task 1: Exited with exit code 1
srun: error: dp-dam05: task 2: Exited with exit code 1
srun: error: dp-dam03: task 0: Exited with exit code 1
